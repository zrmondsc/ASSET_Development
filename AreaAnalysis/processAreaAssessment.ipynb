{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Area Assessment\n",
    "(Optional) This notebook is the third step in the AreaAnalysis workflow. In this notebook we save and export our area analysis features into a postgreSQL database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to Postgres Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write connection string\n",
    "host = \"localhost\"\n",
    "database = \"asset\"\n",
    "user = os.getenv('SQL_USER')\n",
    "password = os.getenv('SQL_PASSWORD')\n",
    "connection_string = f\"postgresql://{user}:{password}@{host}/{database}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sqlalchemy engine\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Input and Output Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set folder path and output path for .csv files\n",
    "inputFolder = \"C:\\\\Users\\\\Zachary\\\\ASSET\\\\resourceAssessment\\\\analysis\\\\data\"\n",
    "folder_path = os.path.join(inputFolder, \"shapefiles\")\n",
    "outputFolder = os.path.join(inputFolder, \"csv\")\n",
    "\n",
    "# Create ouput folder if it doesn't exist\n",
    "if not os.path.exists(outputFolder):\n",
    "    os.makedirs(outputFolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export Analyses to Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store table names\n",
    "table_names = []\n",
    "\n",
    "# Iterate through the files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".shp\"):\n",
    "        # Create the full path to the shapefile (without extension)\n",
    "        file_path = os.path.join(folder_path, os.path.splitext(filename)[0] + \".shp\")\n",
    "\n",
    "        # Read the shapefile using geopandas\n",
    "        gdf = gpd.read_file(file_path)\n",
    "\n",
    "        # Convert column names to lowercase\n",
    "        gdf.columns = [column.lower() for column in gdf.columns]\n",
    "\n",
    "        # Export the GeoDataFrame into PostgreSQL\n",
    "        table_name = os.path.splitext(filename)[0].lower()  # Use the filename as the table name\n",
    "\n",
    "        # add table name to list\n",
    "        table_names.append(table_name)\n",
    "\n",
    "        # add table to PostgreSQL\n",
    "        gdf.to_postgis(name=table_name, con=engine, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query Postgres Databases, Export Queries as .CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the table names, update tables and export to csv\n",
    "\n",
    "for table_name in table_names:\n",
    "    query = '''ALTER TABLE {}\n",
    "                ADD COLUMN geom_text varchar;\n",
    "\n",
    "                UPDATE {}\n",
    "                SET geom_text = ST_AsText(ST_Force2d(geometry), 4);\n",
    "\n",
    "                ALTER TABLE {}\n",
    "                ADD COLUMN geom_centroid geometry;\n",
    "\n",
    "                UPDATE {}\n",
    "                SET geom_centroid = ST_Centroid(ST_Force2d(geometry));\n",
    "\n",
    "                ALTER TABLE {}\n",
    "                ADD COLUMN centroid_text varchar;\n",
    "\n",
    "                UPDATE {}\n",
    "                SET centroid_text = ST_AsText(geom_centroid, 4);\n",
    "\n",
    "                SELECT * FROM {}\n",
    "                ORDER BY objectid'''.format(table_name, table_name, table_name, table_name, table_name, table_name, table_name)\n",
    "\n",
    "    result = engine.execute(query)\n",
    "    rows = result.fetchall()\n",
    "    \n",
    "    # Define the CSV file path within the \"csv\" folder\n",
    "    csv_file_path = os.path.join(outputFolder, f\"{table_name}.csv\")\n",
    "\n",
    "    # Export the query result to a CSV file\n",
    "    with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "\n",
    "       # Write the header\n",
    "        header = result.keys()\n",
    "        csv_writer.writerow(header)\n",
    "        csv_writer.writerows(rows)  # Write the data rows\n",
    "\n",
    "    \n",
    "    print(f\"Table {table_name} exported to CSV: {csv_file_path}\")\n",
    "\n",
    "    print()  # Add a newline between tables\n",
    "\n",
    "print(\"Query execution completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "development",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
